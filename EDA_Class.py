{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.filters.bk_filter import bkfilter\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "import scalecast as sc\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# from scalecast.Forecaster import Forecaster\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import normaltest\n",
    "from hurst import compute_Hc, random_walk\n",
    "from scipy import signal\n",
    "from pmdarima.arima import ndiffs\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "\n",
    "\n",
    "class EDA_TS:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "        \n",
    "    def print_summary(self):\n",
    "        print(\"Data Summary:\")\n",
    "        print(self.data.head())\n",
    "        print('\\n')\n",
    "        print(f\"Number of observations: {len(self.data)}\")\n",
    "        print(f\"Data type: {self.data.dtypes[0]}\")\n",
    "        print(f\"Start date: {self.data.index[0]}\")\n",
    "        print(f\"End date: {self.data.index[-1]}\")\n",
    "        print(f\"Missing values: {self.data.isnull().sum().sum()}\")\n",
    "        \n",
    "        \n",
    "    def plot_time_series(self, title='Time Series Plot', xlabel='Time', ylabel='Value'):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.data)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_acf_pacf(self, lags=30):\n",
    "        fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "        plot_acf(self.data, ax=ax[0], lags=lags)\n",
    "        plot_pacf(self.data, ax=ax[1], lags=lags)\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_seasonal_decomposition(self, model='additive'):\n",
    "        from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "        result = seasonal_decompose(self.data, model=model)\n",
    "        fig, ax = plt.subplots(nrows=4, ncols=1, figsize=(10, 8))\n",
    "        ax[0].set(title='Original Time Series', xlabel='Time', ylabel='Value')\n",
    "        ax[1].set(title='Trend Component', xlabel='Time', ylabel='Value')\n",
    "        ax[2].set(title='Seasonal Component', xlabel='Time', ylabel='Value')\n",
    "        ax[3].set(title='Residual Component', xlabel='Time', ylabel='Value')\n",
    "        ax[0].plot(self.data)\n",
    "        ax[1].plot(result.trend)\n",
    "        ax[2].plot(result.seasonal)\n",
    "        ax[3].plot(result.resid)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def apply_detrending(self,col):\n",
    "        '''\n",
    "        This function helps in detrending the time series using scipy's signal module\n",
    "        \n",
    "        '''\n",
    "        result = signal.detrend(self.data[col])\n",
    "        plt.title('Detrended Series', fontsize=14)\n",
    "        plt.xlabel('length')\n",
    "        plt.ylabel('value')\n",
    "        plt.plot(result)\n",
    "        return result\n",
    "    \n",
    "    def calculate_autocorrelation(self, lag):\n",
    "        return self.data.autocorr(lag=lag)\n",
    "    \n",
    "    \n",
    "    def calculate_partial_autocorrelation(self, lag):\n",
    "        from statsmodels.tsa.stattools import pacf\n",
    "        return pacf(self.data, nlags=lag)[-1]\n",
    "    \n",
    "    \n",
    "    def plot_autocorrelation(self, lags=30):\n",
    "        from statsmodels.graphics.tsaplots import plot_acf\n",
    "        plot_acf(self.data, lags=lags)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def calculate_seasonal_difference(self, period):\n",
    "        return self.data.diff(period).dropna()\n",
    "    \n",
    "    \n",
    "    def calculate_percentage_change(self):\n",
    "        return self.data.pct_change().dropna()\n",
    "    \n",
    "    \n",
    "    def rolling_mean(self, window):\n",
    "        return self.data.rolling(window=window, min_periods=1).mean()\n",
    "    \n",
    "    \n",
    "    def rolling_std(self, window):\n",
    "        return self.data.rolling(window=window, min_periods=1).std()\n",
    "    \n",
    "    \n",
    "    def plot_histogram(self):\n",
    "        plt.hist(self.data, bins='auto')\n",
    "        plt.title('Histogram')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_density(self):\n",
    "        self.data.plot(kind='density')\n",
    "        plt.title('Density Plot')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_boxplot(self):\n",
    "        plt.boxplot(self.data)\n",
    "        plt.title('Box Plot')\n",
    "        plt.xlabel('input')\n",
    "        plt.ylabel('Value')\n",
    "        plt.show()   \n",
    "        \n",
    "    \n",
    "    def calculate_adf_test(self):\n",
    "        \"\"\"\n",
    "        This function calculates the Augmented Dickey-Fuller (ADF) test and prints the results.\n",
    "        This test is used to determine whether a time series is stationary or not. The null hypothesis of the test is \n",
    "        that the series has a unit root (i.e., it is non-stationary). If the p-value is less than a chosen significance \n",
    "        level (e.g., 0.05), then the null hypothesis is rejected and the series is considered stationary.\n",
    "        \n",
    "        \"\"\"\n",
    "        adf_test = adfuller(self.data, autolag='AIC')\n",
    "        print(\"ADF test results:\")\n",
    "        print(f\"ADF test statistic: {adf_test[0]}\")\n",
    "        print(f\"p-value: {adf_test[1]}\")\n",
    "        print(f\"Critical values: {adf_test[4]}\")\n",
    "    \n",
    "    def calculate_kpss_test(self):\n",
    "        \"\"\"\n",
    "        This function calculates the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test and prints the results.\n",
    "        This test is another way to test for stationarity. The null hypothesis is that the series is stationary. If the \n",
    "        p-value is less than the chosen significance level, then the null hypothesis is rejected and the series is considered\n",
    "        non-stationary.\n",
    "                \n",
    "        \"\"\"\n",
    "        kpss_test = kpss(self.data, regression='c')\n",
    "        print(\"KPSS test results:\")\n",
    "        print(f\"KPSS test statistic: {kpss_test[0]}\")\n",
    "        print(f\"p-value: {kpss_test[1]}\")\n",
    "        print(f\"Critical values: {kpss_test[3]}\")\n",
    "    \n",
    "    def plot_lag_plot(self, lag=12):\n",
    "        \"\"\"\n",
    "        This function plots the lag plot of the time series data\n",
    "        \"\"\"\n",
    "        pd.plotting.lag_plot(self.data, lag=lag)\n",
    "        plt.title('lag Plot')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_loess_smoothing(self, col, frac=0.1):\n",
    "        \"\"\"\n",
    "        This function plots the loess smoothing of the time series data\n",
    "        \"\"\"\n",
    "        loess = sm.nonparametric.lowess(self.data[col], self.data.index.values, frac=frac)\n",
    "        plt.plot(self.data.index.values, loess[:, 1], color='red',label = 'Smoothed')\n",
    "        plt.plot(self.data.index.values, self.data, color='blue',label = 'Original')\n",
    "        plt.title(\"Loess Smoothing\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_lowess(self):\n",
    "        \"\"\"\n",
    "        Plots the locally estimated scatterplot smoothing (LOESS) curve.\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        sc.plot_lowess(self.data, ax=ax)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def plot_moving_average(self, window=3):\n",
    "        \"\"\"\n",
    "        This function applies the moving average filter and plots the filtered data\n",
    "        \"\"\"\n",
    "        rolling_mean = self.data.rolling(window=window).mean()\n",
    "        plt.plot(self.data.index.values, rolling_mean, color='red',label = 'Rolling Mean')\n",
    "        plt.plot(self.data.index.values, self.data, color='blue',label = 'Original')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def calculate_granger_causality(self, other_data, maxlag=4):\n",
    "        \"\"\"\n",
    "        This test is used to determine whether one time series can be used to predict another time series. The null hypothesis\n",
    "        is that the first series does not Granger-cause the second series. If the p-value is less than the chosen significance \n",
    "        level, then the null hypothesis is rejected and the first series is considered to Granger-cause the second series.\n",
    "        \n",
    "        \"\"\"\n",
    "        data = pd.concat([self.data, other_data], axis=1)\n",
    "        granger_test = grangercausalitytests(data, maxlag=maxlag)\n",
    "        for lag in range(1, maxlag+1):\n",
    "            print(f\"Lag {lag}\")\n",
    "            print(f\"F-test: {granger_test[lag][0]['ssr_ftest'][0]}\")\n",
    "            print(f\"p-value: {granger_test[lag][0]['ssr_ftest'][1]}\")\n",
    "    \n",
    "    \n",
    "    def apply_baxter_king_filter(self):\n",
    "        '''\n",
    "        The Baxter-King filter is a filter used to smooth a time series by removing high frequency fluctuations. It is \n",
    "        based on a bandpass filter that removes frequencies above a certain cutoff and below a certain low frequency. The \n",
    "        filter has two parameters: the cutoff frequency and the length of the filter. The cutoff frequency determines how \n",
    "        much high frequency noise to remove, and the length of the filter determines the smoothness of the resulting signal.\n",
    "              \n",
    "        '''\n",
    "        cycle = bkfilter(self.data, low=6, high=32, K=12)\n",
    "        plt.plot(self.data, label='Original')\n",
    "        #plt.plot(trend, label='Trend')\n",
    "        plt.plot(cycle, label='Cycle')\n",
    "        plt.title('Baxter-King Filter')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def apply_hodrick_prescott_filter(self):\n",
    "        \n",
    "        '''\n",
    "        The Hodrick-Prescott filter is a filter used to separate a time series into a trend component and a cyclical component.\n",
    "        It is based on a quadratic penalty function that minimizes the sum of squared deviations of the cyclical component from\n",
    "        the trend component. The filter has one parameter, the smoothing parameter, which determines the smoothness of the \n",
    "        resulting trend component.\n",
    "        \n",
    "        '''\n",
    "        cycle, trend = hpfilter(self.data, lamb=1600)\n",
    "        plt.plot(self.data, label='Original')\n",
    "        plt.plot(trend, label='Trend')\n",
    "        plt.plot(cycle, label='Cycle')\n",
    "        plt.title('Hodrick-Prescott Filter')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def calculate_hurst_exponent(self):\n",
    "        \"\"\"\n",
    "        Calculates the Hurst exponent for the time series data.\n",
    "        The hurst exponent is a measure of the “long-term memory” of a time series. It can be used to determine whether \n",
    "        the time series is more, less, or equally likely to increase if it has increased in previous steps. \n",
    "        This property makes the Hurst exponent especially interesting for the analysis of stock data.\n",
    "\n",
    "        Returns:\n",
    "            The Hurst exponent.\n",
    "        \"\"\"\n",
    "        H, _, _ = compute_Hc(self.data.values, kind='change', simplified=True)\n",
    "        return H\n",
    "    \n",
    "    \n",
    "    def calculate_ndiffs(self):\n",
    "        ''' \n",
    "        This function uses ndiffs method from pdmarima and returns the estimated num of diffs\n",
    "        '''\n",
    "        kpss_diffs = ndiffs(self.data, alpha=0.05, test='kpss', max_d=6)\n",
    "        adf_diffs = ndiffs(self.data, alpha=0.05, test='adf', max_d=6)\n",
    "        n_diffs = max(adf_diffs, kpss_diffs)\n",
    "        return ('Estimated number of diffs :' , n_diffs)\n",
    "    \n",
    "     \n",
    "    def normality_test(self):\n",
    "        '''\n",
    "        This test is used to determine whether a time series is normally distributed or not. \n",
    "        \n",
    "        '''        \n",
    "        stat, p = normaltest(self.data)\n",
    "        print(f\"Normality Test Result: statistic={stat}, pvalue={p}\")\n",
    "        \n",
    "        \n",
    "    def ljung_box_test(self,col,lag=None):\n",
    "        '''\n",
    "        This test is used to determine whether a time series has significant autocorrelation at lags up to a certain value \n",
    "        (e.g., 10). The null hypothesis is that the series has no autocorrelation at those lags. If the p-value is less than\n",
    "        the chosen significance level, then the null hypothesis is rejected and the series is considered to have significant \n",
    "        autocorrelation.\n",
    "        \n",
    "        Ideally, we would like to fail to reject the null hypothesis. That is, we would like to see the p-value of the test\n",
    "        be greater than 0.05(say) because this means the residuals for our time series model are independent, which is often an \n",
    "        assumption we make when creating a model.\n",
    "        \n",
    "        Parameters\n",
    "        \n",
    "        lag = list of lags \n",
    "        col = dataframe column  \n",
    "        \n",
    "        return lb_stat and lb_pvalue\n",
    "        \n",
    "        '''\n",
    "        return (acorr_ljungbox(self.data[col], lags=lag))\n",
    "    \n",
    "    \n",
    "    def f_test(self, col, k=2):\n",
    "        '''\n",
    "        This test is used to select the k most significant features from a time series. The null hypothesis is that the \n",
    "        k features are not significant, i.e., the model with k features is not significantly better than the model with \n",
    "        all the features. The alternate hypothesis is that the k features are significant, i.e., the model with k features \n",
    "        is significantly better than the model with all the features.\n",
    "        \n",
    "         The f_test() method returns a list of the k most significant features. Note that this test assumes that the \n",
    "         residuals of the models are normally distributed and have constant variance, so it is important to check the \n",
    "         assumptions before using the test.\n",
    "         \n",
    "         Note - This function takes a timeIndexed input i.e. Set Date as the index column and then use this function\n",
    "        \n",
    "        \n",
    "        '''\n",
    "                \n",
    "        X = np.arange(len(self.data)).reshape(-1, 1)\n",
    "        y = self.data[col]\n",
    "        f_values, p_values = f_regression(X, y)\n",
    "        top_k = np.argsort(f_values)[::-1][:k]\n",
    "        return self.data.columns[top_k], f_values[top_k], p_values[top_k]\n",
    "         \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1I8Of9cenH9nrMv3Ipy5JpAnOYnuWqL8N",
     "timestamp": 1677740749969
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
